{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduce\n\nHello!\n\nThis competition is my first competition.\nAfter studying some notebooks of this competition, I summarized the overall basic process of regression analysis.\n\nThe table of contents is as follows.\n\n1. Data search:\n\n    1) Univariate search:\n        \n    2) Bivariate search:\n\n2. Pre-processing.\n\n    1) Cleansing - Outliers..\n                        \n    2) Cleansing - Processing missing values.\n\n    3) Derivative variable generation\n    \n    4) Change variables.\n\n    5) Dummyization.\n\n3. Modeling.\n\n    1) Create a basic model.\n    \n    2) HyperParameter Tuning: Pipeline + GridSearch(+Optuna) + Cross Validation\n       \n    3) Model learning.\n    \n    4) Ensemble: Stacking and blending.\n    \n    5) The final result.","metadata":{}},{"cell_type":"markdown","source":"## 1. Data search","metadata":{}},{"cell_type":"code","source":"#import some necessary librairies\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt  # Matlab-style plotting\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\")) #check the files available in the directory","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:06.989401Z","iopub.execute_input":"2021-10-23T12:33:06.989753Z","iopub.status.idle":"2021-10-23T12:33:07.029361Z","shell.execute_reply.started":"2021-10-23T12:33:06.989718Z","shell.execute_reply":"2021-10-23T12:33:07.027994Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# read dataset\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:16.567543Z","iopub.execute_input":"2021-10-23T12:33:16.567939Z","iopub.status.idle":"2021-10-23T12:33:16.628793Z","shell.execute_reply.started":"2021-10-23T12:33:16.567896Z","shell.execute_reply":"2021-10-23T12:33:16.627823Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:26.765273Z","iopub.execute_input":"2021-10-23T12:33:26.765575Z","iopub.status.idle":"2021-10-23T12:33:26.793806Z","shell.execute_reply.started":"2021-10-23T12:33:26.765544Z","shell.execute_reply":"2021-10-23T12:33:26.792911Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:31.405942Z","iopub.execute_input":"2021-10-23T12:33:31.406563Z","iopub.status.idle":"2021-10-23T12:33:31.431611Z","shell.execute_reply.started":"2021-10-23T12:33:31.406525Z","shell.execute_reply":"2021-10-23T12:33:31.430689Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### 1) Univariate search","metadata":{}},{"cell_type":"markdown","source":"\nIt is very important to understand the meaning, type, and shape of each variable.\n\nSo I simply divided it into numeric variables and other variables.\n\nI used the '_get_numerical_data' function of numpy to find out the numeric variable.","metadata":{}},{"cell_type":"code","source":"# numeric vars\nnum_cols = set(train._get_numeric_data().columns)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:39.114281Z","iopub.execute_input":"2021-10-23T12:33:39.115306Z","iopub.status.idle":"2021-10-23T12:33:39.120597Z","shell.execute_reply.started":"2021-10-23T12:33:39.115263Z","shell.execute_reply":"2021-10-23T12:33:39.119380Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# other vars\nother_cols = set(train.columns) - set(num_cols)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:47.926250Z","iopub.execute_input":"2021-10-23T12:33:47.926987Z","iopub.status.idle":"2021-10-23T12:33:47.932542Z","shell.execute_reply.started":"2021-10-23T12:33:47.926944Z","shell.execute_reply":"2021-10-23T12:33:47.931286Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"\nYou can also think of numeric variables as continuous variables and other variables as categorical variables.\n\nHowever, there may be categorical variables among numeric variables.\n\nI thought the most obvious way to distinguish them is to read the variable manual and distinguish them directly.","metadata":{}},{"cell_type":"code","source":"# nominal vars\nnominal_vars = [\n    'MSZoning', 'LandContour', 'Utilities',\n    'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n    'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', \n    'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', \n    'GarageType', 'MiscFeature', \n    'SaleType', 'SaleCondition'\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:52.157250Z","iopub.execute_input":"2021-10-23T12:33:52.157609Z","iopub.status.idle":"2021-10-23T12:33:52.164036Z","shell.execute_reply.started":"2021-10-23T12:33:52.157573Z","shell.execute_reply":"2021-10-23T12:33:52.162851Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# ranking vars\nranking_vars = [\n    'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n    'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual',\n    'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'Street', 'Alley',\n    'LandSlope', 'Functional', 'GarageFinish', 'MoSold', 'YrSold', 'PavedDrive', \n    'CentralAir', 'LotShape', 'MSSubClass', \n]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:33:56.448740Z","iopub.execute_input":"2021-10-23T12:33:56.449987Z","iopub.status.idle":"2021-10-23T12:33:56.455456Z","shell.execute_reply.started":"2021-10-23T12:33:56.449942Z","shell.execute_reply":"2021-10-23T12:33:56.454670Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# continuous vars\ncontinue_vars = [\n    'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n    'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n    'BsmtHalfBath', 'FullBath', 'HalfBath', 'TotRmsAbvGrd', 'BedroomAbvGr', 'KitchenAbvGr',\n    'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n    '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'GarageYrBlt', 'YearBuilt', 'YearRemodAdd',\n    'OverallQual'\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:34:02.226166Z","iopub.execute_input":"2021-10-23T12:34:02.226694Z","iopub.status.idle":"2021-10-23T12:34:02.232664Z","shell.execute_reply.started":"2021-10-23T12:34:02.226646Z","shell.execute_reply":"2021-10-23T12:34:02.231328Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"\nThis time, we checked basic statistics for continuous variables.\n\nI found that the minimum value of some variables is zero.","metadata":{}},{"cell_type":"code","source":"train[continue_vars].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:34:10.806470Z","iopub.execute_input":"2021-10-23T12:34:10.807119Z","iopub.status.idle":"2021-10-23T12:34:10.892261Z","shell.execute_reply.started":"2021-10-23T12:34:10.807067Z","shell.execute_reply":"2021-10-23T12:34:10.891548Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"\nAfter that, I explored the distribution of each variable.\n\nFirst, we checked the dependent variable 'SalePrice'.","metadata":{}},{"cell_type":"code","source":"print(f'skew: {train.SalePrice.skew()}')\nprint(f'kurt: {train.SalePrice.kurt()}')\nsns.distplot(train.SalePrice, fit=norm)\nf = plt.figure()\nstats.probplot(train.SalePrice, plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:34:21.925718Z","iopub.execute_input":"2021-10-23T12:34:21.926254Z","iopub.status.idle":"2021-10-23T12:34:22.608742Z","shell.execute_reply.started":"2021-10-23T12:34:21.926217Z","shell.execute_reply":"2021-10-23T12:34:22.607705Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"\"skew\" means skewness and \"kurt\" means kurtosis.\n\nSkewness represents the bias of the distribution, and kurtosis represents the sharpness of the distribution.\n\nI thought about why to check these indicators and concluded that it was because it was an indicator that could judge the normality of the variable.\n\nVariables, especially dependent variables, must follow normality to ensure that the model performs well.\nThe absolute value of skewness is 0-3 and kurtosis is 1-8.\n\nThe histogram is a good chart to check the distribution of variables.\n\nThe qq plot is a good chart for determining normality, and the point must follow the red diagonal.\n\nCurrently, it is difficult to judge that the dependent variable is perfectly normal.","metadata":{}},{"cell_type":"code","source":"train.SalePrice = np.log1p(train.SalePrice)\n\nprint(f'skew: {train.SalePrice.skew()}')\nprint(f'kurt: {train.SalePrice.kurt()}')\nsns.distplot(train.SalePrice, fit=norm)\nf = plt.figure()\nstats.probplot(train.SalePrice, plot=plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:34:27.885321Z","iopub.execute_input":"2021-10-23T12:34:27.885648Z","iopub.status.idle":"2021-10-23T12:34:28.557566Z","shell.execute_reply.started":"2021-10-23T12:34:27.885613Z","shell.execute_reply":"2021-10-23T12:34:28.556705Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"In this case, log conversion is a solution.\n\nLog transformation allows variables to follow normality.","metadata":{}},{"cell_type":"code","source":"X_total = pd.concat((train, test)).drop(['SalePrice'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:34:37.387437Z","iopub.execute_input":"2021-10-23T12:34:37.387821Z","iopub.status.idle":"2021-10-23T12:34:37.417274Z","shell.execute_reply.started":"2021-10-23T12:34:37.387782Z","shell.execute_reply":"2021-10-23T12:34:37.416388Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Draw a histogram of continuous variables.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(6, 6, figsize=(25, 20))\nfor i, c in enumerate(continue_vars):\n    sns.distplot(X_total[c], fit=stats.norm, ax=ax[i//6, i%6])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:34:45.465795Z","iopub.execute_input":"2021-10-23T12:34:45.466370Z","iopub.status.idle":"2021-10-23T12:34:57.776859Z","shell.execute_reply.started":"2021-10-23T12:34:45.466329Z","shell.execute_reply":"2021-10-23T12:34:57.775877Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Some variables seem to be able to follow a normal distribution through log transformation or box cox transformation.\nSome variables have zero. It seems that +1 should be done when converting.","metadata":{}},{"cell_type":"markdown","source":"Draw a bar chart for categorical variables.\n\nSome variables were extremely biased toward one value (0). So they don't seem to be very important variables.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(5, 5, figsize=(25, 15))\nfor i, c in enumerate(nominal_vars):\n    g = sns.barplot(data=pd.DataFrame(X_total[c].value_counts()).reset_index(), x='index', y=c, ax=ax[i//5, i%5])\n    g.set(xticks=[])\n    g.set(title=c)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:35:11.644960Z","iopub.execute_input":"2021-10-23T12:35:11.645251Z","iopub.status.idle":"2021-10-23T12:35:15.868324Z","shell.execute_reply.started":"2021-10-23T12:35:11.645222Z","shell.execute_reply":"2021-10-23T12:35:15.867452Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"#### 2) Bivariate search\n\n\nNow, we have explored the two variables.\n\nFirst, a correlation analysis was conducted to confirm the linear relationship between variables.\n\nThe 'corr' function helps you do this.\n\nSeaborn's heatmap is a chart that helps visualize the results of correlation analysis.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 8))\ncorr = train.corr()\nsns.heatmap(corr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:35:15.870122Z","iopub.execute_input":"2021-10-23T12:35:15.870455Z","iopub.status.idle":"2021-10-23T12:35:17.823272Z","shell.execute_reply.started":"2021-10-23T12:35:15.870420Z","shell.execute_reply":"2021-10-23T12:35:17.822112Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"If you look at the heat map, you can judge that it has a high correlation if it is close to white or black.\n\nI paid attention to variables that have a high correlation with the dependent variable.\n\nOur purpose is to match the value of the dependent variable, and I thought that variables that have a high correlation with the dependent variable would have important characteristics to solve the problem.","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 7))\ntop_corr = train[corr.SalePrice.sort_values(ascending=False)[:10].index].corr()\nsns.heatmap(top_corr, annot=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:35:25.545819Z","iopub.execute_input":"2021-10-23T12:35:25.546164Z","iopub.status.idle":"2021-10-23T12:35:26.368207Z","shell.execute_reply.started":"2021-10-23T12:35:25.546126Z","shell.execute_reply":"2021-10-23T12:35:26.367243Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"I selected only the top 10 variables with the highest correlation with the dependent \nvariable and conducted the correlation analysis again.\n\nI selected only the top 10 variables with the highest correlation with the dependent variable and conducted the correlation analysis again.\n\n\"OverallQual\" and \"GrLiv Area\" are the strongest variables.\n\nGarage Cars and Garage Area are also highly correlated. High correlation between independent variables is not good because it causes multicollinearity.","metadata":{}},{"cell_type":"markdown","source":"\n\nAmong them, I drew a box plot and scatterplot using 'OverallQual' and 'GrLiv Area', which show the highest correlation with the dependent variable.\n\nI understand that they have a strong linear relationship with the dependent variable. So I had an expectation that I could find an outlier.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(data=train[['SalePrice', 'OverallQual']], x='OverallQual', y='SalePrice')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:35:38.765341Z","iopub.execute_input":"2021-10-23T12:35:38.765717Z","iopub.status.idle":"2021-10-23T12:35:39.184102Z","shell.execute_reply.started":"2021-10-23T12:35:38.765682Z","shell.execute_reply":"2021-10-23T12:35:39.182947Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train[['SalePrice', 'GrLivArea']].plot.scatter(x='SalePrice', y='GrLivArea')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:35:42.564636Z","iopub.execute_input":"2021-10-23T12:35:42.565539Z","iopub.status.idle":"2021-10-23T12:35:42.854631Z","shell.execute_reply.started":"2021-10-23T12:35:42.565466Z","shell.execute_reply":"2021-10-23T12:35:42.853990Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Oh! Let's look at the scatter plot with GrLiv Area. \n\nWe can see that the two points with the largest GrLiv Area are completely out of the linear relationship.","metadata":{}},{"cell_type":"markdown","source":"Draw pair plot!","metadata":{"execution":{"iopub.status.busy":"2021-10-13T17:48:43.813485Z","iopub.execute_input":"2021-10-13T17:48:43.81422Z","iopub.status.idle":"2021-10-13T17:48:43.819874Z","shell.execute_reply.started":"2021-10-13T17:48:43.814173Z","shell.execute_reply":"2021-10-13T17:48:43.818733Z"}}},{"cell_type":"code","source":"sns.pairplot(train[corr.SalePrice.sort_values(ascending=False)[:10].index])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:35:47.244639Z","iopub.execute_input":"2021-10-23T12:35:47.245180Z","iopub.status.idle":"2021-10-23T12:36:09.900661Z","shell.execute_reply.started":"2021-10-23T12:35:47.245138Z","shell.execute_reply":"2021-10-23T12:36:09.899296Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## 2. Pre-processing","metadata":{}},{"cell_type":"markdown","source":"#### 1) Cleansing - Outliers","metadata":{}},{"cell_type":"markdown","source":"First, I removed the \"ID\" that is not an outlier but is not needed for analysis.","metadata":{}},{"cell_type":"code","source":"# delete ID\ntrain_id = train.Id\ntest_id = test.Id\ntest_idx = test.index\ntrain.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:36:26.026802Z","iopub.execute_input":"2021-10-23T12:36:26.027169Z","iopub.status.idle":"2021-10-23T12:36:26.038357Z","shell.execute_reply.started":"2021-10-23T12:36:26.027132Z","shell.execute_reply":"2021-10-23T12:36:26.037271Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Next, the two outliers identified in the scatter plot were removed.","metadata":{}},{"cell_type":"code","source":"train.drop(train.GrLivArea.sort_values(ascending=False)[:2].index, axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:36:31.988583Z","iopub.execute_input":"2021-10-23T12:36:31.988979Z","iopub.status.idle":"2021-10-23T12:36:31.997146Z","shell.execute_reply.started":"2021-10-23T12:36:31.988939Z","shell.execute_reply":"2021-10-23T12:36:31.996506Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Let's draw a scatterplot again. It's clean.","metadata":{}},{"cell_type":"code","source":"train[['SalePrice', 'GrLivArea']].plot.scatter(x='SalePrice', y='GrLivArea')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:36:37.244877Z","iopub.execute_input":"2021-10-23T12:36:37.245285Z","iopub.status.idle":"2021-10-23T12:36:37.492606Z","shell.execute_reply.started":"2021-10-23T12:36:37.245255Z","shell.execute_reply":"2021-10-23T12:36:37.491475Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"#### 2) Cleansing - Processing missing values\n\nLog conversion of dependent variables and removal of outliers in training data are over.\n\nThere is no need to stay in the training data anymore.\n\nTherefore, we separate the dependent variable and combine training X and test X.","metadata":{}},{"cell_type":"code","source":"ntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train['SalePrice'].values\nall_data = pd.concat((train, test), axis=0).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:36:40.624684Z","iopub.execute_input":"2021-10-23T12:36:40.625039Z","iopub.status.idle":"2021-10-23T12:36:40.659387Z","shell.execute_reply.started":"2021-10-23T12:36:40.625007Z","shell.execute_reply":"2021-10-23T12:36:40.658419Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Create a missing table using the 'isnull' function.","metadata":{}},{"cell_type":"code","source":"count = all_data.isnull().sum()\npercent = (count / all_data.isnull().count() * 100).sort_values(ascending=False)\nmissing_table = pd.DataFrame({'percent': percent})\nmissing_table.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:36:44.434453Z","iopub.execute_input":"2021-10-23T12:36:44.435078Z","iopub.status.idle":"2021-10-23T12:36:44.478688Z","shell.execute_reply.started":"2021-10-23T12:36:44.435040Z","shell.execute_reply":"2021-10-23T12:36:44.477894Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=percent.index[:30], y=percent[:30])\nplt.title('missing percent', fontsize=15)\nplt.xlabel('features', fontsize=15)\nplt.ylabel('percent', fontsize=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:36:48.604713Z","iopub.execute_input":"2021-10-23T12:36:48.605601Z","iopub.status.idle":"2021-10-23T12:36:49.929741Z","shell.execute_reply.started":"2021-10-23T12:36:48.605556Z","shell.execute_reply":"2021-10-23T12:36:49.928955Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Criteria for processing missing values include deletion and replacement.\n\n'Delete method' deletes the columns in which missing values exist in the simplest and cleanest way.\n\nIn this competition, Rows should not be deleted because missing values may exist in the test data.\n\nThe condition that a column can be deleted is that more than 15% of the column is missing or does not affect the analysis at all.\n\nreplacements is an option that should be considered before deletion.\n\nSimple replacements are again specific value replacements and mean value replacements (average, median, mod, regression), and simple probability replacements (hot deck, cold deck).\n\n'specific value replacements' is possible when there is background knowledge that missing values have some meaning.\n\nIt can be applied mainly to categorical variables. ex) All other values are recorded, but only specific values are recorded.\n\nIn this case, these values usually correspond to special cases or negative meanings or\nit may be a value that may be reluctant to check.\n\nIn this case, the rate of missing values is usually abnormally high. Therefore, if you read the explanation of the variable and fall under the above situation,\nIt replaces it with a specific value.\n\nThe mean value replacement is applied to continuous variables and is used when missing values can be inferred through values of other variables.","metadata":{}},{"cell_type":"code","source":"# specific value replacements\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\n\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\n    \nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\n\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:12.953364Z","iopub.execute_input":"2021-10-23T12:37:12.953706Z","iopub.status.idle":"2021-10-23T12:37:12.986734Z","shell.execute_reply.started":"2021-10-23T12:37:12.953669Z","shell.execute_reply":"2021-10-23T12:37:12.985872Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"All of the above missing values were replaced with specific values.\nThe reason is that we found that their missing values mean Nan or some specific value.\n","metadata":{}},{"cell_type":"code","source":"# mean value replacements\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:31.426012Z","iopub.execute_input":"2021-10-23T12:37:31.426320Z","iopub.status.idle":"2021-10-23T12:37:31.461273Z","shell.execute_reply.started":"2021-10-23T12:37:31.426287Z","shell.execute_reply":"2021-10-23T12:37:31.460482Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"The above missing values are continuous variables and have been replaced with the poorest values.\n\nLot Frontage' will be similar to the value of nearby houses, so it has been replaced with a median value.","metadata":{}},{"cell_type":"code","source":"all_data.drop(['Utilities'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:36.386211Z","iopub.execute_input":"2021-10-23T12:37:36.387155Z","iopub.status.idle":"2021-10-23T12:37:36.397315Z","shell.execute_reply.started":"2021-10-23T12:37:36.387101Z","shell.execute_reply":"2021-10-23T12:37:36.394655Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"'Utilities', 'Condition2', 'RoofMatl', 'Heating' are biased variables. \n\nThey are removed because they are variables that did not significantly affect the analysis.\n\nGarageArea, 1stFlrSF are also removed (High correlation coefficient.).","metadata":{}},{"cell_type":"code","source":"# Complete\nall_data.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:40.246480Z","iopub.execute_input":"2021-10-23T12:37:40.246848Z","iopub.status.idle":"2021-10-23T12:37:40.271372Z","shell.execute_reply.started":"2021-10-23T12:37:40.246814Z","shell.execute_reply":"2021-10-23T12:37:40.270037Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"#### 3) Derivative variable generation\n","metadata":{}},{"cell_type":"markdown","source":"Derivative variables are methods that can improve the quality of analysis.\nThere are several ideas for how to generate derivative variables.\n\n1. It is a continuous variable and means an observation of an object, and if this value is 0, it means that there is no object.\n\nTherefore, it is possible to add categorical variables as to whether or not the object is present.\nCategorical variables with binary values can be stored as 0 and 1.\n\n2. If you can express continuous variables of the same series in association, use a four-line operation.\n\nNew variables can be created. It is similar to calculating BMI with height and weight.\n\nThe above judgment can be used using min and max values after describe.","metadata":{}},{"cell_type":"code","source":"all_data.describe().T[(all_data.describe().T)['min'] == 0].index","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:49.106276Z","iopub.execute_input":"2021-10-23T12:37:49.106859Z","iopub.status.idle":"2021-10-23T12:37:49.260641Z","shell.execute_reply.started":"2021-10-23T12:37:49.106805Z","shell.execute_reply":"2021-10-23T12:37:49.259663Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"all_data['HasMasVnr'] = all_data.MasVnrArea.apply(lambda x: 1 if x else 0)\nall_data['Has2ndFlrSF'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x else 0)\nall_data['HasGarageArea'] = all_data['GarageArea'].apply(lambda x: 1 if x else 0)\nall_data['HasWoodDeckSF'] = all_data['WoodDeckSF'].apply(lambda x: 1 if x else 0)\nall_data['HasOpenPorchSF'] = all_data['OpenPorchSF'].apply(lambda x: 1 if x else 0)\nall_data['HasEnclosedPorch'] = all_data['EnclosedPorch'].apply(lambda x: 1 if x else 0)\nall_data['Has3SsnPorch'] = all_data['3SsnPorch'].apply(lambda x: 1 if x else 0)\nall_data['HasScreenPorch'] = all_data['ScreenPorch'].apply(lambda x: 1 if x else 0)\nall_data['HasPoolArea'] = all_data['PoolArea'].apply(lambda x: 1 if x else 0)\nall_data['HasMiscVal'] = all_data['MiscVal'].apply(lambda x: 1 if x else 0)\n\nall_data['TotalBath'] = all_data['BsmtFullBath'] + all_data['BsmtHalfBath'] * 0.5\\\n+ all_data['FullBath'] + all_data['HalfBath'] * 0.5\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n#all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['2ndFlrSF']\nall_data['TotalBsmtSF'] = all_data['TotalBsmtSF'] + all_data['BsmtFinSF1'] \\\n+ all_data['BsmtFinSF2']","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:55.166849Z","iopub.execute_input":"2021-10-23T12:37:55.167174Z","iopub.status.idle":"2021-10-23T12:37:55.217108Z","shell.execute_reply.started":"2021-10-23T12:37:55.167143Z","shell.execute_reply":"2021-10-23T12:37:55.215989Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"#### 4) Change variables","metadata":{}},{"cell_type":"markdown","source":"Categorical variables must proceed with 'dummy' work.\n\nThe function used at this time is 'get_dummies'. \n\nThis function should be applied to all categorical variables. \n\nTo do this, all categorical variables must be 'str'. Therefore, the types of numerical categorical variables are changed earlier.","metadata":{}},{"cell_type":"code","source":"nominal_vars = list(set(nominal_vars) - set(['Utilities']))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:37:59.884520Z","iopub.execute_input":"2021-10-23T12:37:59.884903Z","iopub.status.idle":"2021-10-23T12:37:59.890101Z","shell.execute_reply.started":"2021-10-23T12:37:59.884859Z","shell.execute_reply":"2021-10-23T12:37:59.889115Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"all_data[nominal_vars] = all_data[nominal_vars].astype(str)\nall_data[ranking_vars] = all_data[ranking_vars].astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:02.246466Z","iopub.execute_input":"2021-10-23T12:38:02.246837Z","iopub.status.idle":"2021-10-23T12:38:02.298522Z","shell.execute_reply.started":"2021-10-23T12:38:02.246792Z","shell.execute_reply":"2021-10-23T12:38:02.297374Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"Among categorical variables, there are variables indicating order or ranking.\n\nThey perform label encoding instead of one hot encoding. Then, the meaning of ranking can be saved.\n\nThe following variables correspond to this.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nfor c in ranking_vars:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:05.365306Z","iopub.execute_input":"2021-10-23T12:38:05.365660Z","iopub.status.idle":"2021-10-23T12:38:05.627177Z","shell.execute_reply.started":"2021-10-23T12:38:05.365624Z","shell.execute_reply":"2021-10-23T12:38:05.626125Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"It is advantageous for analysis that all continuous variables follow normality.\n\nWe select variables with high skewness values.","metadata":{}},{"cell_type":"code","source":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:09.244913Z","iopub.execute_input":"2021-10-23T12:38:09.245270Z","iopub.status.idle":"2021-10-23T12:38:09.286314Z","shell.execute_reply.started":"2021-10-23T12:38:09.245234Z","shell.execute_reply":"2021-10-23T12:38:09.285013Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"We're going to change the boxcox for the variables selected above.\nReduce skewness.","metadata":{}},{"cell_type":"code","source":"skewness = skewness[abs(skewness) > 0.75]\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    all_data[feat] = boxcox1p(all_data[feat], lam)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:12.764876Z","iopub.execute_input":"2021-10-23T12:38:12.765179Z","iopub.status.idle":"2021-10-23T12:38:12.832752Z","shell.execute_reply.started":"2021-10-23T12:38:12.765148Z","shell.execute_reply":"2021-10-23T12:38:12.831744Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"#### 5) Dummyization","metadata":{}},{"cell_type":"markdown","source":"For all categorical types (excluding order variables), get_dummies, which automatically allow one-hot encoding, are applied.","metadata":{}},{"cell_type":"code","source":"all_data = pd.get_dummies(all_data)\nprint(all_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:16.144711Z","iopub.execute_input":"2021-10-23T12:38:16.145030Z","iopub.status.idle":"2021-10-23T12:38:16.178843Z","shell.execute_reply.started":"2021-10-23T12:38:16.145001Z","shell.execute_reply":"2021-10-23T12:38:16.177974Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"## 3. Modeling","metadata":{}},{"cell_type":"markdown","source":"#### 1) Create a basic model\n\nCreate basic models for analysis.\n\nUse lasso, elasticNet, KernelRidge, GradientBoosting, XGBoost, LightGBM","metadata":{}},{"cell_type":"code","source":"X_train = all_data[:ntrain]\nX_test = all_data[ntrain:]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:20.316732Z","iopub.execute_input":"2021-10-23T12:38:20.317670Z","iopub.status.idle":"2021-10-23T12:38:20.322572Z","shell.execute_reply.started":"2021-10-23T12:38:20.317623Z","shell.execute_reply":"2021-10-23T12:38:20.321845Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, PolynomialFeatures, OneHotEncoder\nfrom sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\nfrom sklearn.feature_selection import SelectKBest, f_classif, chi2\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor as rfr, GradientBoostingRegressor as gbr\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom mlxtend.regressor import StackingCVRegressor\n\nimport optuna\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:23.365567Z","iopub.execute_input":"2021-10-23T12:38:23.366445Z","iopub.status.idle":"2021-10-23T12:38:25.909996Z","shell.execute_reply.started":"2021-10-23T12:38:23.366391Z","shell.execute_reply":"2021-10-23T12:38:25.908910Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Create a function that calculates the cross validation score.","metadata":{}},{"cell_type":"code","source":"n_folds = 5\n\ndef rmsle(model, x, y):\n    return np.sqrt(mean_squared_error(y, model.predict(x)))\n\ndef rmsle_cv(model, x, y):\n    #kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    kf = 5\n    rmse =np.sqrt(-cross_val_score(model, x.values, y, scoring='neg_mean_squared_error', cv=kf))\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:26.205048Z","iopub.execute_input":"2021-10-23T12:38:26.205446Z","iopub.status.idle":"2021-10-23T12:38:26.212972Z","shell.execute_reply.started":"2021-10-23T12:38:26.205412Z","shell.execute_reply":"2021-10-23T12:38:26.211936Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"#### 2) HyperParameter Tuning: Pipeline + GridSearch(+Optuna) + Cross Validation","metadata":{}},{"cell_type":"markdown","source":"Build pipelines for Laso, ElasticNet, and Kernel Ridge and parameters to use for grid search.","metadata":{}},{"cell_type":"code","source":"pipe_lasso = Pipeline([\n    ('scaler', RobustScaler()),\n    ('model', Lasso())\n])\npipe_enet = Pipeline([\n    ('scaler', RobustScaler()),\n    ('model', ElasticNet(max_iter=5000))\n])\npipe_krr = Pipeline([\n    ('scaler', RobustScaler()),\n    ('model', KernelRidge())\n])\n\ngrid_param_lasso = [{\n    'model__alpha': 0.0001 * np.arange(1, 100)\n}]\ngrid_param_enet = [{\n    'model__alpha': 0.0001 * np.arange(1, 100),\n    'model__l1_ratio': 0.001 * np.arange(1, 10)\n}]\ngrid_param_krr = [{\n    'model__alpha': 0.0001 * np.arange(1, 100),\n    'model__degree': [1, 2, 3],\n    'model__alpha': [0.6],\n    'model__kernel': ['polynomial'],\n    'model__coef0': [2.5]\n}]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:38:37.387058Z","iopub.execute_input":"2021-10-23T12:38:37.387780Z","iopub.status.idle":"2021-10-23T12:38:37.398173Z","shell.execute_reply.started":"2021-10-23T12:38:37.387713Z","shell.execute_reply":"2021-10-23T12:38:37.397405Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"best_params = {\n    'Lasso': None,\n    'ElasticNet': None,\n    'Kernel Ridge': None\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:39:01.546163Z","iopub.execute_input":"2021-10-23T12:39:01.546828Z","iopub.status.idle":"2021-10-23T12:39:01.552217Z","shell.execute_reply.started":"2021-10-23T12:39:01.546756Z","shell.execute_reply":"2021-10-23T12:39:01.551067Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Grid search is conducted using each pipeline and parameter, and optimal hyperparameters for each model are stored.","metadata":{}},{"cell_type":"code","source":"search_lasso = GridSearchCV(pipe_lasso, grid_param_lasso, scoring='neg_mean_squared_error', n_jobs=-1).fit(X_train, y_train)\nbest_params['Lasso'] = search_lasso.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:00:25.025712Z","iopub.execute_input":"2021-10-23T13:00:25.026100Z","iopub.status.idle":"2021-10-23T13:00:48.779931Z","shell.execute_reply.started":"2021-10-23T13:00:25.026062Z","shell.execute_reply":"2021-10-23T13:00:48.778569Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"search_enet = GridSearchCV(pipe_enet, grid_param_enet, scoring='neg_mean_squared_error', n_jobs=-1).fit(X_train, y_train)\nbest_params['ElasticNet'] = search_enet.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-10-23T12:39:10.345414Z","iopub.execute_input":"2021-10-23T12:39:10.346289Z","iopub.status.idle":"2021-10-23T12:46:19.888482Z","shell.execute_reply.started":"2021-10-23T12:39:10.346227Z","shell.execute_reply":"2021-10-23T12:46:19.887064Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"search_krr = GridSearchCV(pipe_krr, grid_param_krr, scoring='neg_mean_squared_error', n_jobs=-1).fit(X_train, y_train)\nbest_params['Kernel Ridge'] = search_krr.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:00:50.321652Z","iopub.execute_input":"2021-10-23T13:00:50.322195Z","iopub.status.idle":"2021-10-23T13:00:51.817127Z","shell.execute_reply.started":"2021-10-23T13:00:50.322153Z","shell.execute_reply":"2021-10-23T13:00:51.816111Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"Grid search results are as follows.","metadata":{}},{"cell_type":"code","source":"best_params","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:00:58.137254Z","iopub.execute_input":"2021-10-23T13:00:58.137623Z","iopub.status.idle":"2021-10-23T13:00:58.145953Z","shell.execute_reply.started":"2021-10-23T13:00:58.137586Z","shell.execute_reply":"2021-10-23T13:00:58.144908Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"Create a model using grid search results.","metadata":{}},{"cell_type":"code","source":"model_lasso = Pipeline([\n    ('scaler', RobustScaler()),\n    ('model', Lasso(alpha=0.0005))\n])\n\nmodel_enet = Pipeline([\n    ('scaler', RobustScaler()),\n    ('model', ElasticNet(alpha=0.0089, l1_ratio=0.009000000000000001, random_state=3))\n])\n\nmodel_krr = Pipeline([\n    ('scaler', RobustScaler()),\n    ('model', KernelRidge(alpha=0.6,\n                        kernel='polynomial',\n                        degree=2,\n                        coef0=2.5))\n])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:01:01.408642Z","iopub.execute_input":"2021-10-23T13:01:01.409382Z","iopub.status.idle":"2021-10-23T13:01:01.417093Z","shell.execute_reply.started":"2021-10-23T13:01:01.409340Z","shell.execute_reply":"2021-10-23T13:01:01.415999Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"The hyperparameters of tree models are diverse and have many combinations. Their optimization takes a lot of time.\n\n\nSo, I looked for XGBoost's hyperparameters using the Optuna package using early stopping and cross validation.","metadata":{}},{"cell_type":"markdown","source":"The hyperparameters of tree models are diverse and have many combinations. Their optimization takes a lot of time.\n\nI looked for XGBoost's hyperparameters using the Optuna package using early stopping and cross validation.\n\nPreparations: 'optuna', 'functions-partial', objective function\n\nPre-understanding:\n\nOptuna is a framework that helps optimize hyperparameters. An objective function is required.\n\nOptuna's objective function selects a new hyperparameter combination of the model every trial.\n\nOptuna's study object is an object that performs optimization. The optimization of the study object requires a partial object and the number of attempts.\n\nThe partial object is an object that binds X, y with the objective function to be used by optuna.\n\nStudy objects store results that meet the purpose for each trial. Finally, remember the most purposeful hyperparameter combination.\n\nThe trial factor of objective embeds the function of specifying the range and value of hyperparameters. It has a hyperparameter name, range or list as a factor in common.\n<ol>\n    <li>Suggest_int: Select an integer value within the range.</li>\n    <li>Suggest_uniform: Select an equal distribution value within a range.</li>\n    <li>Suggest_discrete_uniform: Select a discrete uniform distribution value within the range.</li>\n    <li>Suggest_loguniform: Select a logarithmic function linear value within a range.</li>\n    <li>Suggest_category: Select a value in the list.</li>\n</ol>","metadata":{}},{"cell_type":"code","source":"def objective_xgbr(trial, X, y):\n    param = {\n        'n_estimators': 2000,\n        'max_depth': trial.suggest_int('max_depth', 3, 11),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.005, 0.01),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 100),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 100),\n        'subsample': trial.suggest_categorical('subsample', list(np.arange(0.4, 1.1, 0.1))),\n        'colsample_bylevel': trial.suggest_categorical('colsample_bylevel', list(np.arange(0.4, 1.1, 0.1))),\n        'n_jobs': -1\n    }\n    model = XGBRegressor(**param)\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    train_scores, test_scores = [], []\n    for train_idx, test_idx in kf.split(X_train):\n        X_tmp_train, X_tmp_test = X_train.iloc[train_idx, :], X_train.iloc[test_idx, :]\n        y_tmp_train, y_tmp_test = y_train[train_idx], y_train[test_idx]\n        model.fit(X_tmp_train, y_tmp_train,\n                 eval_metric=['rmse'], eval_set=[(X_tmp_test, y_tmp_test)],\n                 early_stopping_rounds=30, verbose=0,\n                 callbacks=[optuna.integration.XGBoostPruningCallback(trial, observation_key='validation_0-rmse')])\n        train_score = np.sqrt(mse(y_tmp_train, model.predict(X_tmp_train)))\n        test_score = np.sqrt(mse(y_tmp_test, model.predict(X_tmp_test)))\n        train_scores.append(train_score)\n        test_scores.append(test_score)\n    train_score = np.array(train_scores).mean()\n    test_score = np.array(test_scores).mean()\n    print(f'train score: {train_score}')\n    print(f'test score: {test_score}')\n    return test_score","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:01:08.534622Z","iopub.execute_input":"2021-10-23T13:01:08.535449Z","iopub.status.idle":"2021-10-23T13:01:08.549718Z","shell.execute_reply.started":"2021-10-23T13:01:08.535403Z","shell.execute_reply":"2021-10-23T13:01:08.548362Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"optimizer = partial(objective_xgbr, X=X_train, y=y_train)\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(optimizer, n_trials=100)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-23T13:01:13.086830Z","iopub.execute_input":"2021-10-23T13:01:13.087438Z","iopub.status.idle":"2021-10-23T13:23:27.982396Z","shell.execute_reply.started":"2021-10-23T13:01:13.087390Z","shell.execute_reply":"2021-10-23T13:23:27.981618Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"We used Optuna to find XGBoost's optimal hyperparameters.\n\nWe can check the RMSE by XGBoost's attempt.","metadata":{}},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:24:35.386967Z","iopub.execute_input":"2021-10-23T13:24:35.388038Z","iopub.status.idle":"2021-10-23T13:24:35.711962Z","shell.execute_reply.started":"2021-10-23T13:24:35.387983Z","shell.execute_reply":"2021-10-23T13:24:35.710815Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"We can also observe the results for each hyperparameter.","metadata":{}},{"cell_type":"code","source":"optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:24:49.674055Z","iopub.execute_input":"2021-10-23T13:24:49.674616Z","iopub.status.idle":"2021-10-23T13:24:50.143284Z","shell.execute_reply.started":"2021-10-23T13:24:49.674563Z","shell.execute_reply":"2021-10-23T13:24:50.142461Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# XGBoost HyperParameters\nstudy.best_params","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:24:57.165006Z","iopub.execute_input":"2021-10-23T13:24:57.165456Z","iopub.status.idle":"2021-10-23T13:24:57.176138Z","shell.execute_reply.started":"2021-10-23T13:24:57.165424Z","shell.execute_reply":"2021-10-23T13:24:57.174714Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"model_xgbr = XGBRegressor(colsample_bytree=0.4, learning_rate=0.00898718134841855, max_depth=8, \n                             n_estimators=2200, reg_alpha=0.036142628805195254, reg_lambda=0.03188665185506858,\n                             subsample=0.6, random_state =42)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:25:09.893650Z","iopub.execute_input":"2021-10-23T13:25:09.894046Z","iopub.status.idle":"2021-10-23T13:25:09.901382Z","shell.execute_reply.started":"2021-10-23T13:25:09.894008Z","shell.execute_reply":"2021-10-23T13:25:09.900096Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"I haven't done grid search for Gradient Boosting and LightGBM yet (I referred to other notebooks).","metadata":{}},{"cell_type":"code","source":"model_gbr = gbr(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:25:25.353260Z","iopub.execute_input":"2021-10-23T13:25:25.354112Z","iopub.status.idle":"2021-10-23T13:25:25.359800Z","shell.execute_reply.started":"2021-10-23T13:25:25.354072Z","shell.execute_reply":"2021-10-23T13:25:25.358850Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"model_lgbm = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:25:31.105986Z","iopub.execute_input":"2021-10-23T13:25:31.106446Z","iopub.status.idle":"2021-10-23T13:25:31.113419Z","shell.execute_reply.started":"2021-10-23T13:25:31.106413Z","shell.execute_reply":"2021-10-23T13:25:31.112545Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"I create a stacking model.","metadata":{}},{"cell_type":"code","source":"stack_gen = StackingCVRegressor(regressors=(model_lgbm, model_lasso, model_enet, model_krr, model_gbr),\n                               meta_regressor=model_xgbr,\n                               use_features_in_secondary=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:25:35.004632Z","iopub.execute_input":"2021-10-23T13:25:35.004991Z","iopub.status.idle":"2021-10-23T13:25:35.009748Z","shell.execute_reply.started":"2021-10-23T13:25:35.004946Z","shell.execute_reply":"2021-10-23T13:25:35.009103Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"#### 3) Model learning.\n\n\nCross validation is conducted for all models.","metadata":{}},{"cell_type":"code","source":"models = [\n    model_lasso, model_enet, model_krr, model_gbr, model_xgbr, model_lgbm\n]\ncross_score = {\n    'Lasso': 0,\n    'ElasticNet': 0,\n    'Kernel Ridge': 0,\n    'GradientBoosting': 0,\n    'XGBoost': 0,\n    'LightGBM': 0,\n}\n\nfor idx, model in enumerate(models):\n    cross_score[list(cross_score.keys())[idx]] = rmsle_cv(model, X_train, y_train).mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:25:40.785971Z","iopub.execute_input":"2021-10-23T13:25:40.786618Z","iopub.status.idle":"2021-10-23T13:27:29.125421Z","shell.execute_reply.started":"2021-10-23T13:25:40.786555Z","shell.execute_reply":"2021-10-23T13:27:29.124704Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"cross_score","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:27:40.405446Z","iopub.execute_input":"2021-10-23T13:27:40.405803Z","iopub.status.idle":"2021-10-23T13:27:40.413683Z","shell.execute_reply.started":"2021-10-23T13:27:40.405754Z","shell.execute_reply":"2021-10-23T13:27:40.412800Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"Now, the final learning is conducted using the training data.","metadata":{}},{"cell_type":"code","source":"for model in models:\n    model = model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:27:47.425618Z","iopub.execute_input":"2021-10-23T13:27:47.426806Z","iopub.status.idle":"2021-10-23T13:28:13.677012Z","shell.execute_reply.started":"2021-10-23T13:27:47.426728Z","shell.execute_reply":"2021-10-23T13:28:13.676267Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"#### 4) Ensemble: Stacking and blending.","metadata":{}},{"cell_type":"markdown","source":"Learn the stacking model.","metadata":{}},{"cell_type":"code","source":"stack_gen = stack_gen.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:28:28.385437Z","iopub.execute_input":"2021-10-23T13:28:28.385839Z","iopub.status.idle":"2021-10-23T13:29:48.537315Z","shell.execute_reply.started":"2021-10-23T13:28:28.385795Z","shell.execute_reply":"2021-10-23T13:29:48.536462Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"I weighted each model for the final result. \n\nI previously gave a higher weight to the model with excellent cross-validation performance.","metadata":{}},{"cell_type":"code","source":"def blend(X):\n    return ((0.15 * model_lasso.predict(X)) + \\\n            (0.15 * model_enet.predict(X)) + \\\n            (0.05 * model_krr.predict(X)) + \\\n            (0.15 * model_xgbr.predict(X)) + \\\n            (0.15 * model_lgbm.predict(X)) + \\\n            (0.35 * stack_gen.predict(np.array(X))))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:29:59.026479Z","iopub.execute_input":"2021-10-23T13:29:59.026802Z","iopub.status.idle":"2021-10-23T13:29:59.034099Z","shell.execute_reply.started":"2021-10-23T13:29:59.026748Z","shell.execute_reply":"2021-10-23T13:29:59.032671Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"np.sqrt(mse(y_train, blend(X_train)))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:30:04.749852Z","iopub.execute_input":"2021-10-23T13:30:04.750217Z","iopub.status.idle":"2021-10-23T13:30:05.284163Z","shell.execute_reply.started":"2021-10-23T13:30:04.750180Z","shell.execute_reply":"2021-10-23T13:30:05.283445Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"np.sqrt(mse(y_train, stack_gen.predict(X_train)))","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:30:09.737319Z","iopub.execute_input":"2021-10-23T13:30:09.737891Z","iopub.status.idle":"2021-10-23T13:30:10.063673Z","shell.execute_reply.started":"2021-10-23T13:30:09.737838Z","shell.execute_reply":"2021-10-23T13:30:10.062740Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"#### 5) The final result","metadata":{}},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = test_id\nsub['SalePrice'] = score = np.expm1(blend(X_test))\nsub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T13:30:28.213099Z","iopub.execute_input":"2021-10-23T13:30:28.213401Z","iopub.status.idle":"2021-10-23T13:30:28.803709Z","shell.execute_reply.started":"2021-10-23T13:30:28.213371Z","shell.execute_reply":"2021-10-23T13:30:28.802824Z"},"trusted":true},"execution_count":87,"outputs":[]}]}